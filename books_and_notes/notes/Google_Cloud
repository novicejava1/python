======================================================================================
Compute Engine
======================================================================================

- VM's can be created using boot disk image, book disk snapshot or container image
- E2, N1, N2, N2D virtual machines provide good balance between price and performance
- C2 virtual machines are compute optimized for high performance CPU intensive compute workload applications
- M2 virtual machines are memory optimized providing high memory and are great for in memory databases
- A2 virtual machines are based on A100 GPU Accelerated optimized for very high demanding applications
- Confidential virtual machines  allow to encrypt most sensitive data in the cloud while its being processed
- Shielded VM's offer security features like UEFI compliant firmware, secure boot, and vTPM protected measured boot
- These machines provide easy integration with other cloud services, easy to scale globally, help in save money and get more value
- Live migration of VM's between host systems is possible without downtime
- Sole tenant nodes support Bring your own license applications
- VM's can be created using Console, gcloud cli or using an API
- VM contains a boot loader, boot file system, an OS image
- Shielded VM image with a local SSD, can't shield data with integrity monitoring or the virtual platform trusted module (vTPM)
- If the name of the instance matches with name of the persistent disk, that persistent disk attaches as the book disk to instance
- Cloud Console adds a network tag to your instance and creates the corresponding ingress firewall rule that allows all incoming traffic when Allow HTTP or HTTPs selected
- From boot snapshots create custom images and then create instance from custom image. Custom images can create book disks for instances quickly and efficiently then snapshots
- Non boot snapshots are backups of secondary persistent disks that instances use only for data storage
- Service account is a special account whose credentials you can use in application code to access other Google cloud services
- If an appllcation on VM needs access to Google cloud services, First create a service account and then set up instance to run as a service account
- By default Google cloud creates an auto mode VPC network called default for each project

- Preemptible instances cost much lower than the normal instances. Compute Engine might stop (Preempt) these instances if it requires access to those resources for other tasks. Also these instances will always stop after 24 hours
- Preemptible instances are recommended for fault tolerant applicaitons that can withstand instance preemption (set by Availability Policy - Preemptibility - ON)
- Preemptible instance host maintenance action is set to terminate
- Preemptive instance can be set to run a script to perform clean up action and copy a checkpoint file to cloud storage bucket
- Preemptible status of an instance can be obtained from instance metadata scheduling/preemptible which provide True if its ON
- To check whether an instances was preempted or not can be done from logs by applying filter computue.instances.prempted or from instance metadata instanc/preempted
- Weekends and nights are best time to run large preemptible VM clusters
- Its good to have a combination of regular and preemptible instances in cluster to ensure work proceeds at adequate pace

- Sole tenant node groups are physical server that run VM's only from a single project
- Sole tenant node template is a regional resource that specified properties for each node in a node group. Sole tenant node groups are created based on the tempate
- Managed instance groups (MIG's) lets to provision a group of identical sole-tenant VM's
- To bring instances with existing licenses to Google cloud
    Prepare image as per license agreement
    Activate licenses
    Import virtual disk files and create images from disk files
    Create sole tenant node tempates
    Create sole tenant node groups from node tempaltes
    Provision VM's on node groups from virtual disk imported
    Track license usage of VM's using Google tools
    Report to vendor for license consumption
- Sole tenant node groups and VM's usage can be tracked by Google IAP desktop
- Node group autoscaler helps to automatically manage the size of the node group
- CPU overcommit lets to schedule instances that can share their spare CPU cycles with each other
- Workloads with high CPU utilization are not good candidates for CPU overcommit because they will not have spare utilization cycles for other overcommitted VMs to utilize
- Boot disk size should be limited to 2TB to account for MRB partitioning
- Boot disks can be attached and detached from the instances which are in stopped state

- By default Compute engine creates firewall rules that allow TCP/22 for SSH access.
- We can store the host keys as guest attributes on the Linux instances (host keys are nothing but the remote servers keys from where we try to connect to VM)
- Storing host keys as guest attributes imporives security and protects against MITM attack
- The guest OS agent automatically publishes the host keys as a guest attributes
- Enable OS login for SSH access using third party SSH client tool
- Connection to an instance without an external IP address is possible in three ways
    Connect to instances over VPN connection using internal instance name
    Connect through a bastion host machine using the internal IP address
    Connect using Identity aware proxy for TCP forwarding (wraps SSH connection within HTTPS )
- Bastion host also lets to connect to instances on other peered VPC networks
- Instances can be SSHed using the service account which uses the SSH credentials of the service account
- Transferring files to instances is possible with below methods
    Cloud Storage bucket is a convenient intermediate transfer point between instances regardless of the OS
    Transfer files using SSH in browser
    Using the gcloud CLI

- Access to VM instances can be provided to users or applications
- User access to VM can be provided using one of the below methods
    OS Login
    Managing SSH keys in metadata
    Temporarily grant user access to an instance
- Application access to VM can be provided using service accounts
- OS login uses Compute engine IAM roles to manage SSH access to linux instances
- OS login is currently not supported by GKE, Fedora CoreOS, Windows and SQL servers

- Persistent disks are network attached storage devices
- Zonal persistent disks are available as either Standard Hard disk (HDD) or Solid state drives (SSD)
- Zonal persistent disks size can only be increased not decreased
- Backup the persistent disk using Snapshots to prevent data loss
- We can attach upto 127 secondary non-boot zonal persistent disks with a total attached capacity limit of 257 TB per instance
- Disk clones are useful for duplicating production data to debug without disturbing production
- For scenarios where data protection is critical as in backup and disaster recovery use Sanpshots instead of disk clones
- Boot disks and secondary disks with MBR partition tables can resize only up to 2 TB
- Zonal persistent disk can be auto delete when the associated VM instance is deleted
- Non boot zonal persistent disks can be shared between multiple VM instances in read only mode for sharing static data
- For sharing dynamic storage space between multiple instances one of following options can be used
    Connect instances to Cloud storage
    Connect instances to Filestore
    Create Network File server on Compute Engine
- Persistent disks type can be changed by first creating a snapshot and again creating Persistent disk with new type from the snapshot

- Regional persistent disk cannot be used as boot disks
- Regional persistent disk support force attachment to another VM in case of event of zonal failure
- Regional persistent disk cannot be created from a image. Min size of Regional persistent disk is 200GB
- Regional persistent disk can be shared between multiple instance same as Zonal persistent disks
- Zonal persistent disk can be migrated to Regional persistent disk by using snapshot

- Compute engine offers always encrypted local SSD block storage for VM's
- Local SSD disk size 375GB, max 24 Local SSD per instance, total capacity of 9TB per instance
- Local SSD are physically attached to the VM's
    Superior performance
    High IOPS
    Low latency
- Local SSD provide good performance but at the cost of availability, durability and flexibility. 
- Local SSD storage are not automatically replicated so data may be lost in case instance stops for any reason
- Local SSD are suitable for temporary storage such as caches, processing space, low value data
- Local SSDs are available through both SCSI and NVMe interfaces.
- To reach maximum performance limits with 16 or 24 local SSD partitions, use a VM with 32 or more vCPUs

- Cloud storage is a flexible, scalable and durable storage option for VM instances
- Writing and reading data from Cloud storage buckets is possible using gsutil or Cloud storage API
- Cloud storage buckets can be mounted as file system using Cloud storage FUSE tool
- Cloud storage buckets are objecct storage
- Persistent disk performance can be monitored using Google Cloud Monitoring integrated solution

- RAM Disks can be created from the memory allocated to an instance for low latency and high throughput
- RAM Disks alone do not provide any storage redundancy or flexibility
- Before restart of an instance with an in memory RAM disk write data from RAM disk to replicated storeage
- tmpfs of desired size can be mounted to create a RAM disk
- Custom script can be added to do rsync from RAM disk to persistent disk for backup
- IOPS oriented workloads like Databases have usage patterns of random access to data
- Throughput oriented workloads like streaming operations such as Hadoop jobs benefit from fast sequential reads and larger IO sizes
- Benchmarking persistent disk performance is done better using FIO rather than DD
- glcoud recommender can be used to identify Persistent disk which are idle and not in use. It can help in taking required action on them. We can either delete the PD's or Snapshot the PD and delete the disk

- Backup of Zonal PD's and Regional PD's should be done at regular intervals using Snapshot to avoid data loss
- Snapshots are global resources, they are accessible by any resource within a project. Snapshots can be shared across projects
- Compute Engine stores multiple copies of each snapshot across multiple locations with automatic checksums to ensure data integrity
- Snapshots are incremental and automatically compressed 
- Snapshots can be stored in either Cloud storage multi-regional location or Cloud storage regional location

- VM instance can have an external IP address and internal IP address
- Static external IP can be reserved or an ephemeral external IP address can be promoted to become a static IP address for an instance
- There are two types of external IP address
    Regional IP address - Used for VM instances
    Global IP address - Used for global load balaners like HTTPS, SSL Proxy, TCP proxy

- Compute engine supplies an up to date Container Optimized OS with Docker installed and launches your container when VM starts
- GKE lets deploy multiple containers and groups of containers for each VM instance which allocate resources more efficiently

- By default Google Cloud projects come with a single user, the original project creator. No other users have access to project
- New user can be added as team member of a project or to a specific resource and grant permissions using IAM roles
- Team member can be a valid individual user with google account, a Google Group, a Service account or Google workspace domain
- IAM provides three types of roles
    predefined roles
    basic roles
    custom roles
- Resources inherit policies of their parent resources in Google cloud resource hierarchy. The effective policy is the union both policies at resource and parent level
- Basic IAM roles map directly to the legacy project owner, editor, viewer roles
- IAM policies lets to manage IAM roles on the resources instead of managing roles at the project level
- IAM lets us give more granular access to specific google cloud resources and prevent unwanted access to other resources
- IAM lets you control who (identity) has what (roles) permission to which resources by setting IAM policies
- A Policy is a collection of bindings. A binding binds one or more members to a single role




    














